I will be maintaining this page to list down the recent works that I find interesting or relevant to understand the ongoing reserach in the field. I pass no judgement of quality of these works.

**Learning Disentangled Represenations**  
[NeurIPS 2019](Disentangled_updates.md)  
[ICLR 2019](disentangled_iclr_2019.md)  
[ICLR 2020](disentanglement_iclr_20t.md)

**Adversarial Defense/Robustness Papers**

**@NeurIPS 2019**  



**@ICCV 2019**


**@ICLR 2020**
- [Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier](https://openreview.net/pdf?id=BkgWahEFvr)  
- [On Need for Topology-Aware Generative Models for Manifold-Based Defenses](https://openreview.net/pdf?id=r1lF_CEYwS)  
- [Certified Defenses for Adversarial Patches](https://openreview.net/pdf?id=HyeaSkrYPH)  
- [Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks](https://openreview.net/pdf?id=SyevYxHtDB)  
- [BREAKING CERTIFIED DEFENSES: SEMANTIC ADVERSARIAL EXAMPLES WITH SPOOFED ROBUSTNESS CERTIFICATES](https://openreview.net/pdf?id=HJxdTxHYvB)  
- [Enhancing Adversarial Defense by k-Winners-Take-All](https://openreview.net/pdf?id=Skgvy64tvr)  
- [Adversarial Training and Provable Defenses: Bridging the Gap](https://openreview.net/pdf?id=SJxSDxrKDr)  
- [Defending Against Physically Realizable Attacks on Image Classification](https://openreview.net/forum?id=H1xscnEKDr)  
- [Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks](https://openreview.net/forum?id=ByxtC2VtPB)  
- [Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks](https://openreview.net/forum?id=SyevYxHtDB)





