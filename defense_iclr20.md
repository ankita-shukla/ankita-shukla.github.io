- [Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier](https://openreview.net/pdf?id=BkgWahEFvr)  
- [On Need for Topology-Aware Generative Models for Manifold-Based Defenses](https://openreview.net/pdf?id=r1lF_CEYwS)  
- [Certified Defenses for Adversarial Patches](https://openreview.net/pdf?id=HyeaSkrYPH)  
- [Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks](https://openreview.net/pdf?id=SyevYxHtDB)  
- [BREAKING CERTIFIED DEFENSES: SEMANTIC ADVERSARIAL EXAMPLES WITH SPOOFED ROBUSTNESS CERTIFICATES](https://openreview.net/pdf?id=HJxdTxHYvB)  
- [Enhancing Adversarial Defense by k-Winners-Take-All](https://openreview.net/pdf?id=Skgvy64tvr)  
- [Adversarial Training and Provable Defenses: Bridging the Gap](https://openreview.net/pdf?id=SJxSDxrKDr)  
- [Defending Against Physically Realizable Attacks on Image Classification](https://openreview.net/forum?id=H1xscnEKDr)  
- [Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks](https://openreview.net/forum?id=ByxtC2VtPB)  
- [Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks](https://openreview.net/forum?id=SyevYxHtDB)
